# Group assignment

The group assignment has been designed for groups of 6 students. Groups with 5 or 4 students are also possible.
Please use Brightspace to form your groups.

In addition to this document, in Brightspace you will find a separate zip file with the dataset.

## Learning goals

In this group assignment you will apply the skills which you have learned to a raw real-world dataset.  
You will practice:

- Dividing the work into small tasks and assigning them to team members.
- Using git to manage the project.
- Working with raw (not cleaned) datasets.
- Understanding the structure of the dataset.
- Processing multiple files (e.g. all files in a directory).
- Reading different file formats (e.g. TSV, CSV; possibly gzipped).
- Getting data from a remote server (JSON format).
- Handling time/date columns (epoch time, time zones).
- Providing a class interface to the database.
- Creating a relational database (through [SQLAlchemy](https://www.sqlalchemy.org/) library).
- Inserting data into the database.
- Querying the database.
- Writing small programs in Python which can be used as command line tools (optimally with the [Click](https://click.palletsprojects.com/en/7.x/) library).
- Signalling errors to the user.
- Processing the dataset with the [pandas](https://pandas.pydata.org/) library.
- Visualizing the data with the [matplotlib](https://matplotlib.org/) or [seaborn](https://seaborn.pydata.org/) library.
- Documenting the code.
- Providing an overview of the project in a README file.

Moreover, you're welcome to:

- Comment on privacy/security issues related to the dataset.
- Comment on the quality of the dataset.
- Comment on experiences with ChatGPT and/or Copilot.

## Project context

To achieve better energy efficiency, many people want to measure and control the energy usage of devices installed in their homes.
Many recent home automation devices provide remote access to their state. For example, a smart wall light socket ([example](https://www.fibaro.com/en/products/switches/)) can be:

- controlled remotely (commands: turn on, turn off, toggle, always turn off 5 minutes after turning on, etc.),
- monitored (is state on or off, after how many minutes will it turn off, etc.).

## Data sources

A uniform communication standard with home automation devices is emerging ([Matter](https://en.wikipedia.org/wiki/Matter_(standard))) but not yet commonly available. Consequently, in practice, data from different devices needs to be carefully filtered, adjusted and integrated.

The data in this assignment originates from a single-family, gas-heated home located in Nordwijk, NL.
Messages generated by (approx. 30) smart home devices have been collected over 13 months.
The devices include: sockets, wall switches, light bulbs, temperature/humidity sensors, motion sensors, door sensors, etc.
They generate daily more than 1000 messages about their state (e.g. "current temperature is 20.1째C", "the light has been turned on", "the door has been opened", "motion has been detected", etc.)

The messages are provided by several sources listed below.

### Source `SmartThings`

The [SmartThings](https://www.smartthings.com/) platform collect messages from many smart home devices:

- The messages are provided as multiple files in TSV format.
- At least one file per day is collected.
- File names start with `smartthingsLog`.
- Rows with identical messages might be present in multiple files.

Columns:

- `epoch` - message timestamp (as text representing Universal Time UTC/Zulu)
- `capability` - what the message describes (e.g. `temperatureMeasurement`)
- `value` and `unit` provide the device state readings (e.g. `20.1` and `째C`)
- `deviceLabel` - name of the device given by the user
- `location` - where in the house the device is mounted
- `deviceId` - a unique identifier of the device. 

Example (a fragment of a `smartthingsLog` file):

```
2023-01-22T14:00:27Z	energyMeter	energy	7.605	kWh	Outlet: hot water	kitchen	6e0a5d1b-c958-43494b-bdb0b4-f91c482ba3e5
2023-01-22T14:06:31Z	relativeHumidityMeasurement	humidity	35	%	Sensor: bathroom2	bathroom	9ef8bd74-fe1a-444b4c-808c83-49f2b30c7ead
2023-01-22T14:07:47Z	temperatureMeasurement	temperature	17.3	째C	Button: living room	living room	ac41896f-acb1-4f4c42-a1a2a0-54ae7fb9c182
2023-01-22T14:12:45Z	temperatureMeasurement	temperature	2.7	째C	Sensor: garden	garden	b83fde14-d073-41484c-878d83-ad5c3f29b471
2023-01-22T14:12:45Z	relativeHumidityMeasurement	humidity	79	%	Sensor: garden	garden	b83fde14-d073-41484c-878d83-ad5c3f29b471
2023-01-22T14:12:46Z	illuminanceMeasurement	illuminance	86	lux	Sensor: garden	garden	b83fde14-d073-41484c-878d83-ad5c3f29b471
2023-01-22T14:57:10Z	motionSensor	motion	active		Sensor: bathroom	bathroom	38a046fc-d5f6-404e4d-b9b1b7-b7af6285493e
2023-01-22T14:59:28Z	motionSensor	motion	inactive		Sensor: bathroom	bathroom	38a046fc-d5f6-404e4d-b9b1b7-b7af6285493e
```

### Source `P1e`

`P1e` source provides messages about electricity usage:

- Multiple files with readings from a smart meter in CSV format.
- Collected approx. biweekly.
- 15-minutes resolution.
- File names start with `P1e-`.
- Rows with identical readings might be present in multiple files.
- The files are compressed with `gzip` (check the `open` function in `gzip` module).

Columns:

- Reading time (in Europe/Amsterdam timezone)
- Total energy usage [kWh] in low-cost hours (`T1`)
- Total energy usage [kWh] in high-cost hours (`T2`)
- (ignore other columns)

Example (a fragment of a `P1e-` file):

```
time,Electricity imported T1,Electricity imported T2,Electricity exported T1,Electricity exported T2
2022-12-01 00:00,7937.977,6284.179,0.000,0.000
2022-12-01 00:15,7938.024,6284.179,0.000,0.000
2022-12-01 00:30,7938.075,6284.179,0.000,0.000
2022-12-01 00:45,7938.178,6284.179,0.000,0.000
```

### Source `P1g`

`P1g` source provides messages about gas usage:

- Multiple files with readings from a smart meter.
- Collected approx. biweekly.
- 15-minutes resolution.
- File names start with `P1g-`.
- Rows with identical readings might be present in multiple files.
- The files are compressed with `gzip` (check the `open` function in `gzip` module).

Columns:
- Reading time (as text, in Europe/Amsterdam timezone)
- Total gas usage [m3].

### Source `OpenWeatherMap`

The [OpenWeatherMap](https://openweathermap.org/) is a web site providing past weather data and predicted weather "for now". Data can be obtained in JSON or tabular formats. Some variables (e.g. temperature and humidity) can be obtained with 1 hour resolution. Look into the course materials for examples of how to access the data.

## Database design

Data from the sources are not uniform. They are provided in different formats (TSV, CSV, JSON) and they may contain duplicated entries. The goal of the project is to remove duplicates and store all the data in a relational database (SQLite). The database should contain at least two related tables, for example:

- `messages` keeping messages from all sources normalized to one format
- `sources` keeping information about the source files

Each message should refer to a source file from which it originates. For duplicated messages, only one source should be stored.

Date/time columns should be stored in the database as an integer number (called `epoch`) representing the [Unix Time](https://en.wikipedia.org/wiki/Unix_time) (number of seconds since 1970-01-01 00:00:00 UTC). Libraries allowing to convert between different date/time formats and epoch time are available in Python.

## Database access module

The database should be accessed through a class interface:

- The class should be called `HomeMessagesDB`.
- The class should be implemented in a separate file called `home_messages_db.py`.
- An instance of the class should be initialized with the database file name (in SQLAlchemy format, e.g. `sqlite:///myhome.db`). The database file should be created if it does not exist.
- The class should provide methods to:
    - Create the database (if it does not exist).
    - Insert data into the database (as needed by the command-line tools, see below).
    - Query the database (as needed by the reports, see below).
- Any access to the database should be done through the methods of the class (no direct access to the database anywhere else in the code).

## Command-line tools to insert data into the database

The task is to write command-line tools inserting data into the database:

- For each data source there should be a separate tool (named: `smartthings.py`, `p1e.py`, `p1g.py`, `openweathermap.py`).
- The tools should be Python scripts (`.py`) which can be executed from the terminal/shell command line.
- Two students should be responsible for each tool and each student should contribute to at least one tool.
- To get access to the database the tool should `import home_messages_db` module, create an instance of the `HomeMessagesDB` class and communicate with the database through the methods of the class.
- When used without any arguments, or with `-h` or `--help` option, the tool should print a help message describing the tool and its options (see the [Click](https://click.palletsprojects.com/en/7.x/) library).
- When used with wrong arguments, the tool should raise an exception which would print an error message.

### SmartThings tool

This tool should insert data from the SmartThings files into the database.  

Here is the description of the arguments and options of the tool (this should be printed when the tool is called with `-h` or `--help` option):
```
Usage:
    smartthings.py [OPTIONS] smartthingsLog.1.tsv [smartthingsLog.2.tsv...]

Output options:
    -d DBURL insert into the project database (DBURL is a SQLAlchemy database URL)
```

For example, to load the data from the file `smartthingsLog.2023-01-30_15:25:47.tsv` into the database `myhome.db` use the command:

```bash
smartthings.py -d sqlite:///myhome.db smartthingsLog.2023-01-30_15:25:47.tsv
```

And to load the data from all the files starting with `smartthingsLog.` into the database `myhome.db` use the command:

```bash
smartthings.py -d sqlite:///myhome.db smartthingsLog.*.tsv
```

### P1e tool

This tool should insert electricity consumption data from the P1e files into the database.

Here is the description of the arguments and options of the tool (this should be printed when the tool is called with `-h` or `--help` option):
```
Usage:
    p1e.py [OPTIONS] P1e-2022-12-01-2023-01-10.csv.gz [...]

Output options:
    -d DBURL insert into the project database (DBURL is a SQLAlchemy database URL)
```

For example, to load the data from the file `P1e-2022-12-01-2023-01-10.csv.gz` into the database `myhome.db` use the command:

```bash
p1e.py -d sqlite:///myhome.db P1e-2022-12-01-2023-01-10.csv.gz
```

And to load the data from all the files matching the filename pattern `P1e-*.csv.gz` into the database `myhome.db` use the command:

```bash
p1e.py -d sqlite:///myhome.db P1e-*.csv.gz
```

### P1g tool

This tool should insert gas consumption data from the P1g files into the database. It should follow the same design as the P1e tool.

### OpenWeatherMap tool

Weather data can be obtained from the [OpenWeatherMap](https://openweathermap.org/) web site. These data are needed for at least one report but they do not need to be stored in the database, they can be downloaded on demand. The group should decide whether to store the data in the database or not. If the data are stored in the database, then there should be a command line tool which follows a similar design as the other tools.

### Database tool

The group may decide to create a separate tool which would allow to initialize the database (create the tables). It should be described in the README file how to initialize the database and how to use all the tools to fill the database with the data from the source files.

## Data analyses

The task is to write several Python notebooks reports (`.ipynb`) with analyses of the data from the database:

- Each report should discuss at least one question about the data, contain at least one visualization and at least one table (e.g. a table with statistics or a table with the results of a query)
- Two students should be responsible for each report and each student should contribute to at least one notebook report.
- The names of the report files should start with `report_` (e.g. `report_gas_usage.ipynb`).
- To get access to the data the report should `import home_messages_db`, create an instance of the `HomeMessagesDB` class and communicate with the database through the methods of the class.
- At least one of the reports should use weather data obtained from the weather server.

Here are some example questions which can be studied in a report (you're welcome to create your own questions):

- How to identify time intervals when nobody is at home?
- What is the distribution of the energy and gas usage over the day?
- Are there weekly patterns in the energy and gas usage?
- When heating is off, how quickly does the temperature drop? Does this depend on the outside temperature?
- How long per day are the lights in the living room on? Does it depend on the length of the day?
- The devices are not ideal - how to identify intervals when a device is not working?
- What is the difference between the measured (garden) and predicted (from the weather server; for Nordwijk) temperature?

## Submission

The project should be delivered as a dedicated, **private** git repository containing the following files:

- `README.md` file with the description of the project, project files and instructions how to run the tools and the reports.
- `home_messages_db.py` file with a documented implementation of the `HomeMessagesDB` class (and eventually other classes).
- The command line tools (Python scripts).
- The reports (Python notebooks).

The GitHub repository should be shared with the teachers (`SzMK-LUMC` and `Mo-LUMC`).

The SSH link to the repository should be submitted as a solution of the *SSH link to the Group Assignment repository* assignment in *Brightspace*.
In the following Python code edit your group id/name and the SSH link to your GitHub group assignment repository.  
Run the edited Python code to generate `group_assignment.json` file. In *Brightspace*, submit this file.

```python
import json

info = {
    "groupName": "group_99",                      # [1] put student ids of the group members
    "sshGitHub": "git@github.com:LUMC/EfDS.git"   # [2] copy here the SSH address of the group assignment GitHub repository
                                                  #     (you may find it when you press the green Code button)
}

with open( "group_assignment.json", "w" ) as f:   # [3] run this cell to generate group_assignment.json file
    json.dump( obj = info, fp = f )
                                                  # [4] submit the assignments.json file as a solution of
                                                  #     "SSH link to the Group Assignment repository"
                                                  #     assignment
```

## Grading

The primarily goal of the project is to learn how to work in a group on a software project. Therefore, the central criteria for grading the project is whether the designed class, the command line tools and the reports are consistent with each other.

Moreover, the project will be graded based on the following criteria:

- The README file is well written and contains all the necessary information about the project (and also about who is responsible for which report and command line tools).
- The SQLite database is present and is used to store the data. No duplicate data are stored in the database. There are at least two related tables in the database.
- The command line tools work as expected, are well documented and easy to use. Error messages are generated and informative.
- The reports are well written, easy to understand and contain interesting analyses (with a plot and a table).
- The project is delivered on time.
- Time/date is handled well (e.g. the time zone is taken into account). Temperatures/humidity are in valid ranges.
- Bonus points for valuable comments on security, data quality or experiences using large-language-models (Chat-GPT, GitHub Copilot, etc).

Each file of the project will be graded separately. The `README.md` and the `home_messages_db.py` files will be considered to be developed by each student of the group. The reports and the command line tools will be considered to be developed by specified students. The final grade for each student will be the average of the grades for the individual files for which the student is responsible.
